{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JeoomW6-41VN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras.regularizers import l1, l2\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.datasets import mnist\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "\n",
        "\n",
        "x_train = x_train.reshape(-1, 28, 28, 1)  # Shape: (60000, 28, 28, 1)\n",
        "x_test = x_test.reshape(-1, 28, 28, 1)\n",
        "\n",
        "\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    zoom_range=0.2,\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKtWkZLe5IMk",
        "outputId": "a8aa781b-9314-4bcc-c694-82f682690d06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(128, activation='relu', kernel_regularizer=l2(0.01)),  # L2 Regularization\n",
        "    Dropout(0.5),  # Dropout Layer\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3,restore_best_weights=True)\n",
        "\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "history = model.fit(datagen.flow(x_train, y_train),\n",
        "                    epochs=10,\n",
        "                    validation_data=(x_test, y_test),\n",
        "                    callbacks=[early_stopping])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qa0TQjHu5IxA",
        "outputId": "50ef8bb2-ca8c-4f10-d4e3-161ef37d6169"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 17ms/step - accuracy: 0.7234 - loss: 1.4200 - val_accuracy: 0.9185 - val_loss: 0.5098\n",
            "Epoch 2/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 19ms/step - accuracy: 0.8334 - loss: 0.7593 - val_accuracy: 0.9297 - val_loss: 0.4677\n",
            "Epoch 3/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 15ms/step - accuracy: 0.8472 - loss: 0.7095 - val_accuracy: 0.9336 - val_loss: 0.4455\n",
            "Epoch 4/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 15ms/step - accuracy: 0.8495 - loss: 0.6969 - val_accuracy: 0.9469 - val_loss: 0.4101\n",
            "Epoch 5/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 15ms/step - accuracy: 0.8551 - loss: 0.6710 - val_accuracy: 0.9420 - val_loss: 0.4040\n",
            "Epoch 6/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 15ms/step - accuracy: 0.8613 - loss: 0.6617 - val_accuracy: 0.9426 - val_loss: 0.4080\n",
            "Epoch 7/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 15ms/step - accuracy: 0.8597 - loss: 0.6514 - val_accuracy: 0.9442 - val_loss: 0.3986\n",
            "Epoch 8/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 15ms/step - accuracy: 0.8626 - loss: 0.6559 - val_accuracy: 0.9419 - val_loss: 0.4038\n",
            "Epoch 9/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 15ms/step - accuracy: 0.8606 - loss: 0.6573 - val_accuracy: 0.9477 - val_loss: 0.3971\n",
            "Epoch 10/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 15ms/step - accuracy: 0.8656 - loss: 0.6448 - val_accuracy: 0.9429 - val_loss: 0.3997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Regression\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "sBvVi26v5U0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=sns.load_dataset('iris')\n",
        "df.head()\n",
        "\n",
        "\n",
        "x=df.drop(columns=['sepal_length'])\n",
        "y=df['sepal_length']\n",
        "\n",
        "\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)\n",
        "\n",
        "\n",
        "le=LabelEncoder()\n",
        "x_train['species']=le.fit_transform(x_train['species'])\n",
        "x_test['species']=le.transform(x_test['species'])\n"
      ],
      "metadata": {
        "id": "SuTRnnWE5VVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "noise_factor = 0.1\n",
        "x_train_noisy = x_train + noise_factor * np.random.normal(size=x_train.shape)\n",
        "x_test_noisy = x_test + noise_factor * np.random.normal(size=x_test.shape)\n",
        "\n",
        "\n",
        "model=Sequential([\n",
        "    Dense(64,activation='relu',input_shape=(x_train.shape[1],)),\n",
        "    Dropout(0.5),\n",
        "    Dense(32,activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1)\n",
        "])\n",
        "early_stopping=EarlyStopping(monitor='val_loss',patience=3,restore_best_weights=True)\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),loss='mean_squared_error',metrics=['mae'])\n",
        "history=model.fit(x_train_noisy,y_train,epochs=25,validation_data=(x_test_noisy,y_test),callbacks=early_stopping)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgeguYxq5gWe",
        "outputId": "cbd25287-bb76-4ac8-d6b8-1a963a723dcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 29.7662 - mae: 5.3206 - val_loss: 30.9563 - val_mae: 5.5044\n",
            "Epoch 2/25\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 25.7172 - mae: 4.9300 - val_loss: 26.9445 - val_mae: 5.1381\n",
            "Epoch 3/25\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 21.9550 - mae: 4.5267 - val_loss: 22.8896 - val_mae: 4.7376\n",
            "Epoch 4/25\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 19.3869 - mae: 4.2320 - val_loss: 18.9610 - val_mae: 4.3129\n",
            "Epoch 5/25\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 16.7393 - mae: 3.8464 - val_loss: 15.2658 - val_mae: 3.8709\n",
            "Epoch 6/25\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 15.6908 - mae: 3.6992 - val_loss: 11.8676 - val_mae: 3.4154\n",
            "Epoch 7/25\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 12.0359 - mae: 3.1395 - val_loss: 8.6943 - val_mae: 2.9255\n",
            "Epoch 8/25\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 9.3993 - mae: 2.7554 - val_loss: 6.0093 - val_mae: 2.4307\n",
            "Epoch 9/25\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 9.2889 - mae: 2.5926 - val_loss: 3.8510 - val_mae: 1.9377\n",
            "Epoch 10/25\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 5.1970 - mae: 1.9082 - val_loss: 2.2013 - val_mae: 1.4437\n",
            "Epoch 11/25\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 6.5113 - mae: 2.0233 - val_loss: 1.1877 - val_mae: 1.0155\n",
            "Epoch 12/25\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 6.0397 - mae: 1.9915 - val_loss: 0.6263 - val_mae: 0.7026\n",
            "Epoch 13/25\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 5.6680 - mae: 1.8723 - val_loss: 0.3863 - val_mae: 0.5352\n",
            "Epoch 14/25\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 5.6833 - mae: 1.8894 - val_loss: 0.3240 - val_mae: 0.4866\n",
            "Epoch 15/25\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 6.2015 - mae: 1.9932 - val_loss: 0.3402 - val_mae: 0.5020\n",
            "Epoch 16/25\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 6.4200 - mae: 2.0462 - val_loss: 0.4494 - val_mae: 0.5953\n",
            "Epoch 17/25\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 4.6213 - mae: 1.7297 - val_loss: 0.6516 - val_mae: 0.7260\n"
          ]
        }
      ]
    }
  ]
}